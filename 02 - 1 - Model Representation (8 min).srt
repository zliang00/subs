1
00:00:02,338 --> 00:00:04,677
最初に学ぶ学習アルゴリズムは線形回帰だ。

2
00:00:06,956 --> 00:00:09,234
このビデオでは、そのモデルがどのようなもので、さらに重要なのは、

3
00:00:09,234 --> 00:00:14,801
総合的に教師あり学習のプロセスがどのようなものかを見ていく。
では、動機付けをする例として、

4
00:00:14,801 --> 00:00:20,036
住宅の価格を予測する例を使う。

5
00:00:20,036 --> 00:00:25,205
ここで使うデータセットは、オレゴン州ポートランド市の住宅価格のものだ。
ここにデータセットをプロットする。

6
00:00:25,205 --> 00:00:30,833
いくつかの家のそれぞれの広さと、それらが売れたそれぞれの価格の範囲だ。

7
00:00:30,833 --> 00:00:35,872
このデータセットを元に、家を売ろうとしている友人がいたとして、

8
00:00:35,872 --> 00:00:41,238
そう、その人の家の広さが 1250 平行フィートで、

9
00:00:41,238 --> 00:00:46,459
いくらで家が売れるか教えたいとする。さて、できることの一つは、

10
00:00:46,648 --> 00:00:53,039
モデルを当てはめることだ。例えば、このデータに直線を当てはめる。
こんな感じに。

11
00:00:53,039 --> 00:00:59,168
そして、それに基づき、友人に言えることは、そう、例えば

12
00:00:59,168 --> 00:01:03,575
その家はだいたい 22万ドルぐらいで売れるだろうということだ。

13
00:01:03,575 --> 00:01:08,834
これは教師あり学習アルゴリズムの一例だ。これが教師あり学習だという理由は

14
00:01:08,834 --> 00:01:14,287
それぞれのサンプルに対して「正解」が与えられているからだ。

15
00:01:14,287 --> 00:01:19,351
つまり、実際の家が、データセット中のそれぞれの家が、

16
00:01:19,351 --> 00:01:24,441
実際にいくらで売れたのか、ということだ。さらに、これは回帰問題の一例だ。

17
00:01:24,441 --> 00:01:29,545
回帰という言葉は、私たちが予測しようとしているのが
実数値の出力であるという事実を指している。

18
00:01:29,545 --> 00:01:34,586
つまり価格だ。
そして思い出してほしいのは、もう一つの最も一般的なタイプの教師あり学習問題は、

19
00:01:34,586 --> 00:01:39,006
分類問題と呼ばれるもので、

20
00:01:39,006 --> 00:01:45,202
それは離散値出力を予測するものだった。

21
00:01:45,202 --> 00:01:52,032
例えば、癌腫瘍を見て、どれが悪性でどれが良性かを判別する場合だ。
それは 0 か 1 の値で、つまり離散値だ。

22
00:01:52,032 --> 00:01:57,087
もっと形式的に言うと、教師あり学習ではデータセットがあり、

23
00:01:57,087 --> 00:02:02,018
そしてこのデータセットは訓練セットと呼ばれる。
だから住宅の価格の例では、訓練セットとして

24
00:02:02,018 --> 00:02:07,386
それぞれの家の価格があり、課題は、このデータから住宅の価格を

25
00:02:07,386 --> 00:02:11,907
予測するよう学習することだ。
では、このコースを通して使ういくつかの表記方法を定義する。

26
00:02:11,907 --> 00:02:16,100
かなりの数のシンボルを定義していく。

27
00:02:16,100 --> 00:02:20,075
すべてのシンボルを今すぐ覚えなくてもいい。
しかし、コースが進行するにつれて、こうした表記方法を覚えていくと便利だ。

28
00:02:20,075 --> 00:02:24,267
では、このコースを通して、小文字の m を使って

29
00:02:24,267 --> 00:02:28,897
訓練サンプルの数を表す。このデータセットでは、この表には 47 行ある。

30
00:02:28,897 --> 00:02:34,366
ということは 47 件の訓練サンプルがあるということで、m = 47 となる。

31
00:02:34,366 --> 00:02:39,497
小文字の x を使って、入力変数を表す。

32
00:02:39,497 --> 00:02:44,290
これはよく特徴とも言われる。これはここの x だ。 
この下に並ぶのが、入力する特徴だ。

33
00:02:44,290 --> 00:02:49,556
そして y を使って予測する出力変数、目標変数を表す。

34
00:02:49,556 --> 00:02:54,552
そしてそれはこの二番目の列だ。もう少し表記方法について。

35
00:02:54,552 --> 00:03:05,749
(x, y) と表記して一件の訓練サンプルを表す。

36
00:03:05,749 --> 00:03:12,068
だから、この表の各行が一件の訓練サンプルに対応する。

37
00:03:12,068 --> 00:03:19,708
そして、特定の訓練サンプルを指すときには、この表記方法 (x(i), y(i)) を使い、

38
00:03:25,322 --> 00:03:30,935
これを使って i 番目の訓練サンプルを指す。だから、この添え字 i は

39
00:03:30,935 --> 00:03:37,864
ここにあるが、これは指数ではない。いいかな。
この (x(i), y(i)) では、添え字の i は

40
00:03:37,864 --> 00:03:44,873
括弧で囲まれていて、それは単に訓練セットへのインデックスで、

41
00:03:44,873 --> 00:03:51,629
このテーブルの i 行目を示す。いいかな。
だから、これは x の i 乗、y の i 乗という意味ではない。

42
00:03:51,629 --> 00:03:58,216
(x(i), y(i)) は単にこの表の i 番目の列を示すだけだ。つまり、例えば、x(1) は

43
00:03:58,216 --> 00:04:04,972
最初の訓練サンプルの入力値を指すので、それは 2104 だ。
それは、この 最初の行の x の値だ。

44
00:04:04,972 --> 00:04:11,685
x(2) は = 1416 で、これが二番目の x の値だ。

45
00:04:11,685 --> 00:04:17,385
そして y(1) は = 460、最初の y の値、最初の訓練サンプルだ。

46
00:04:17,385 --> 00:04:24,526
それが(1) の示す意味だ。前にも触れた通り、時々、質問をして、

47
00:04:24,526 --> 00:04:28,345
皆さんが自分の理解を確認できるようにする。

48
00:04:28,345 --> 00:04:34,044
数秒後にこのビデオに選択問題がビデオに表示される。

49
00:04:34,044 --> 00:04:40,362
そうしたら、マウスを使って、あなたが正しいと思う答えを選択してほしい。

50
00:04:40,362 --> 00:04:45,124
訓練セットによって定義されるのは何か。これが教師あり学習アルゴリズムの仕組みだ。

51
00:04:45,124 --> 00:04:50,513
開始点に住宅価格の訓練セットのような訓練セットがある。

52
00:04:50,513 --> 00:04:55,715
そしてそれを学習アルゴリズムに読み込ませる。学習アルゴリズムの仕事は、

53
00:04:55,715 --> 00:05:00,101
ある関数を出力することで、慣習的にこれは小文字の h で表記される。

54
00:05:00,101 --> 00:05:06,574
h は 仮説（hypothesis）の略だ。そして仮説の仕事は、関数として

55
00:05:06,574 --> 00:05:12,471
入力として家の広さを受け取り、例えば、友人が売ろうとしている新しい家の広さなど、

56
00:05:12,471 --> 00:05:18,368
そして 与えられた x の値に対して

57
00:05:18,368 --> 00:05:31,630
それに相当する家の推定価格 y を出力しようとする。

58
00:05:31,630 --> 00:05:37,729
つまり、h は x から y に対応付けする関数だ。
よく人から聞かれるのは、

59
00:05:37,729 --> 00:05:42,121
なぜこの関数が仮説と呼ばれるかだ。
皆さんの中には、仮説という言葉の意味を知っている人もいると思う。

60
00:05:42,121 --> 00:05:46,744
辞書からとか、あるいは科学からとか何とか。実は、機械学習では、

61
00:05:46,744 --> 00:05:51,310
これは機械学習の初期に使われた名前で、それがなんとなく定着してしまった。

62
00:05:51,310 --> 00:05:55,239
このような関数にはそれほどふさわしい名前ではないかもしれない。

63
00:05:55,239 --> 00:05:59,978
家の広さを予測価格に対応付けするような場合には。

64
00:05:59,978 --> 00:06:04,543
仮説という用語は、多分、一番適切な名前ではないだろう。
しかし、人々が使う標準的な用語として、

65
00:06:04,543 --> 00:06:09,362
機械学習では使われている。
だから、なぜ人々かそのように呼ぶのかは、あまり気にしないでほしい。

66
00:06:09,362 --> 00:06:14,332
学習アルゴリズムを設計する際に、次に決めなければいけないことは、

67
00:06:14,332 --> 00:06:20,540
どのようにこの仮説 h を表現するかだ。

68
00:06:20,540 --> 00:06:26,978
今回以降の数回のビデオでは、初期の選択として、仮説の表現を以下のようにする。

69
00:06:26,978 --> 00:06:33,009
h を以下のように表現する。そしてこれをこのように書く。

70
00:06:33,009 --> 00:06:39,254
h theta(x) = theta 0 + theta 1 掛ける x。

71
00:06:39,254 --> 00:06:45,441
そして簡略表記として、h theta(x) と書く代わりに、h(x) と略すこともある。

72
00:06:45,441 --> 00:06:51,627
しかし、たいていの場合は、添え字の theta を書く。
そしてこれを図としてプロットすると、

73
00:06:51,627 --> 00:06:58,210
これの意味は、 y を x の線形関数として予測するということだ。

74
00:06:58,210 --> 00:07:04,634
これがデータセットで、この関数が行っているのは、

75
00:07:04,634 --> 00:07:11,698
y がなんらかの x の直線の関数だと予測しているのだ。

76
00:07:11,698 --> 00:07:18,450
h(x) = theta 0 + theta 1  x。分かるかな。ではなぜ線形関数なのか。

77
00:07:18,450 --> 00:07:23,405
時には、もっと複雑な、例えば非線形関数を当てはめたいこともある。

78
00:07:23,405 --> 00:07:28,298
しかし、この線形のケースは簡単な基本となるケースなので、

79
00:07:28,298 --> 00:07:32,943
まずはこの例では最初に線形関数に当てはめ、いずれはこれを発展させて、

80
00:07:32,943 --> 00:07:37,403
もっと複雑なモデル、もっと複雑な学習アルゴリズムにしていく。

81
00:07:37,403 --> 00:07:42,628
また、このモデルを特に指示す名前をつけたい。このモデルは線形回帰といい、

82
00:07:42,628 --> 00:07:48,271
この例は、実は変数が一つの場合の線形回帰で、その変数は x だ。

83
00:07:48,271 --> 00:07:53,914
すべての価格を一つの変数 x で予測するものだ。

84
00:07:53,914 --> 00:07:58,852
そしてこのモデルのもう一つの名前は単回帰だ。

85
00:07:58,852 --> 00:08:04,400
そして単回帰の単は変数が一つであるということを意味する。これが線形回帰だ。

86
00:08:04,400 --> 00:08:09,760
次のビデオでは、このモデルをどのように実装していくかを話す。
