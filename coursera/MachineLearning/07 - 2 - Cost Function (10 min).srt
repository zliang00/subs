1
00:00:00,144 --> 00:00:02,011
このビデオでは

2
00:00:02,011 --> 00:00:03,990
正規化がどう機能するか、の背後にある

3
00:00:03,990 --> 00:00:05,771
主要な直感をお伝えしたい。

4
00:00:05,771 --> 00:00:07,386
そして、私たちが正規化を用いる時に

5
00:00:07,386 --> 00:00:11,724
使うコスト関数を書き下していく。

6
00:00:11,780 --> 00:00:13,327
これらのスライドに描いた

7
00:00:13,327 --> 00:00:14,916
手書きの例で、

8
00:00:14,950 --> 00:00:17,642
その直感の一部をお伝えできると思う。

9
00:00:17,700 --> 00:00:19,608
だが、より良い方法は、

10
00:00:19,608 --> 00:00:21,192
自分自身で見てみることだろう。

11
00:00:21,192 --> 00:00:22,643
正規化がどう機能するかを、

12
00:00:22,643 --> 00:00:25,869
自分で実装してみて、自分のところで機能するかを見ることだ。

13
00:00:25,869 --> 00:00:26,888
そして、その後に

14
00:00:26,888 --> 00:00:28,603
適切な課題を解けば、

15
00:00:28,603 --> 00:00:30,053
正規化が、実際に

16
00:00:30,053 --> 00:00:33,927
正しく動くかを、自分で確かめることができる。

17
00:00:33,930 --> 00:00:36,519
では、直感とはこうだ。

18
00:00:36,519 --> 00:00:38,233
前回のビデオでは、

19
00:00:38,233 --> 00:00:39,771
このデータに二次関数を

20
00:00:39,771 --> 00:00:41,420
フィッティングさせると、

21
00:00:41,420 --> 00:00:44,283
データにかなり良くフィットすることを見てきた。

22
00:00:44,283 --> 00:00:45,286
一方でもし、非常に高次の

23
00:00:45,310 --> 00:00:47,175
多項式でフィッティングすると、

24
00:00:47,210 --> 00:00:48,823
結局、訓練セットには

25
00:00:48,850 --> 00:00:50,111
非常に良くフィットした曲線を

26
00:00:50,111 --> 00:00:51,760
得られるかもしれないが、

27
00:00:51,760 --> 00:00:53,381
だが実際には、

28
00:00:53,420 --> 00:00:54,497
データにオーバーフィットしてしまっていて、

29
00:00:54,497 --> 00:00:57,225
あまりうまく一般化できないだろうことも見た。

30
00:00:57,900 --> 00:01:00,453
以下を考えてみよう。

31
00:01:00,453 --> 00:01:02,088
パラメータのシータ3とシータ4に

32
00:01:02,088 --> 00:01:04,753
ペナルティを与えて、非常に小さくしてみよう。

33
00:01:04,753 --> 00:01:06,543
それはつまりこういうことだ。

34
00:01:06,543 --> 00:01:09,676
これが最適化目的の関数だ。

35
00:01:09,690 --> 00:01:10,859
あるいは最適化問題で、

36
00:01:10,870 --> 00:01:12,574
それは通常の、二乗誤差の

37
00:01:12,580 --> 00:01:15,526
コスト関数を最小化するというものだ。

38
00:01:15,526 --> 00:01:17,350
この目的の関数を

39
00:01:17,370 --> 00:01:19,125
変更して、これに

40
00:01:19,160 --> 00:01:23,291
1000 シータ3の二乗 を加えて、

41
00:01:23,291 --> 00:01:28,334
さらに1000シータ4の二乗を加えよう。

42
00:01:28,334 --> 00:01:32,354
1000というのは適当な大きな数字を書いただけだ。

43
00:01:32,354 --> 00:01:33,538
いま、この関数を

44
00:01:33,540 --> 00:01:35,127
最小化すると、

45
00:01:35,140 --> 00:01:36,688
この新しいコスト関数を

46
00:01:36,710 --> 00:01:38,620
小さくする唯一の方法は、

47
00:01:38,620 --> 00:01:40,769
シータ3とシータ4を

48
00:01:40,769 --> 00:01:42,133
小さくすることだ。

49
00:01:42,133 --> 00:01:43,264
何故なら、1000掛けるシータ3の

50
00:01:43,264 --> 00:01:44,956
項があるから、

51
00:01:44,970 --> 00:01:48,103
この新しいコスト関数も大きくなってしまう。

52
00:01:48,140 --> 00:01:49,245
だからこの新しいコスト関数を

53
00:01:49,245 --> 00:01:50,402
最小化するなら、

54
00:01:50,402 --> 00:01:52,107
結局シータ3を0に近づけ、

55
00:01:52,110 --> 00:01:53,776
シータ4を0に近づけ、

56
00:01:53,776 --> 00:01:56,700
そしてここの、これら二つの項を

57
00:01:56,700 --> 00:02:03,206
取り除くしかない。

58
00:02:03,206 --> 00:02:03,206


59
00:02:03,710 --> 00:02:05,282
そうすると、

60
00:02:05,290 --> 00:02:06,783
シータ3とシータ4が0に近いなら、

61
00:02:06,783 --> 00:02:07,973
残っているのは

62
00:02:07,973 --> 00:02:09,643
二次関数だ。

63
00:02:09,643 --> 00:02:11,089
つまり結局は、

64
00:02:11,110 --> 00:02:13,343
二次関数に、足すことの

65
00:02:13,343 --> 00:02:15,463
小さな項による寄与、の関数で、

66
00:02:15,463 --> 00:02:17,856
データにフィッティングすることになる。

67
00:02:17,860 --> 00:02:20,207
小さな項とはシータ3, シータ4の項で、これは非常に0に近い。

68
00:02:20,207 --> 00:02:27,293
つまり結局、

69
00:02:27,293 --> 00:02:29,386
本質的には二次関数となり、それは良いことだ。

70
00:02:29,386 --> 00:02:30,544
何故なら、これはより良い

71
00:02:30,544 --> 00:02:34,060
仮説だから。

72
00:02:34,104 --> 00:02:36,666
この具体例では、二つのパラメータに

73
00:02:36,700 --> 00:02:39,023
非常に大きな値でのペナルティを与えた場合の

74
00:02:39,023 --> 00:02:41,446
効果を見てきた。

75
00:02:41,446 --> 00:02:46,510
より一般的には、正規化の背後にあるアイデアはこういうものだ。

76
00:02:46,980 --> 00:02:48,924
そのアイデアとは、

77
00:02:48,924 --> 00:02:50,303
パラメータとして小さな値だった時は、

78
00:02:50,303 --> 00:02:53,083
パラメータが

79
00:02:53,083 --> 00:02:55,250
小さな値だったら、

80
00:02:55,250 --> 00:02:57,866
それは通常、ややよりシンプルな仮説に

81
00:02:57,866 --> 00:03:00,386
対応している。

82
00:03:00,386 --> 00:03:02,279
つまり、さきほどの例では、

83
00:03:02,279 --> 00:03:04,024
シータ3とシータ4だけにペナルティを与えた。

84
00:03:04,024 --> 00:03:05,666
そしてこれら二つが

85
00:03:05,666 --> 00:03:07,046
0に近づけば

86
00:03:07,046 --> 00:03:08,450
それはよりシンプルな仮説であり、

87
00:03:08,480 --> 00:03:12,549
ほぼ二次関数となる。

88
00:03:12,549 --> 00:03:13,991
だがより広く、すべてのパラメータに

89
00:03:13,991 --> 00:03:15,989
ペナルティを与えると、

90
00:03:15,989 --> 00:03:17,416
それもまた、よりシンプルな仮説を

91
00:03:17,420 --> 00:03:19,076
与えようとする試みになる。

92
00:03:19,110 --> 00:03:20,943
何故なら、、、

93
00:03:20,943 --> 00:03:22,380
これらのパラメータが

94
00:03:22,410 --> 00:03:23,700
0に近づけば、

95
00:03:23,700 --> 00:03:26,105
二次関数になるのだから。

96
00:03:26,105 --> 00:03:29,038
より一般の場合でも、

97
00:03:29,038 --> 00:03:30,493
より小さいパラメータの値は

98
00:03:30,530 --> 00:03:32,536
より滑らかな関数に対応する、と

99
00:03:32,540 --> 00:03:34,416
いうことが示せる。

100
00:03:34,416 --> 00:03:36,780
つまり、よりシンプルになる。

101
00:03:36,780 --> 00:03:41,667
従って、よりオーバーフィットしづらくなるということだ。

102
00:03:41,680 --> 00:03:43,245
何故すべてのパラメータを

103
00:03:43,245 --> 00:03:45,441
小さく保つことが、

104
00:03:45,441 --> 00:03:46,944
よりシンプルな仮説に対応するのか？

105
00:03:46,960 --> 00:03:48,916
その理由が良く分からないかもしれないのは、

106
00:03:48,916 --> 00:03:51,572
私の方でも分かっている。

107
00:03:51,590 --> 00:03:52,784
自分で実際に実装しないで

108
00:03:52,784 --> 00:03:54,477
理解するのは、

109
00:03:54,480 --> 00:03:56,446
なかなか難しい。

110
00:03:56,470 --> 00:03:58,247
だが、シータ3とシータ4を

111
00:03:58,247 --> 00:03:59,610
小さくする、という例が

112
00:03:59,650 --> 00:04:01,230
どのようによりシンプルな仮説を

113
00:04:01,230 --> 00:04:02,535
与えるかを見たことで、

114
00:04:02,540 --> 00:04:04,776
何か納得できるような、

115
00:04:04,800 --> 00:04:06,314
少なくとも何となくそう思えることを、

116
00:04:06,330 --> 00:04:09,320
期待している。

117
00:04:09,320 --> 00:04:11,476
具体的な例を見ていこう。

118
00:04:12,010 --> 00:04:13,873
住居の価格の予測では、

119
00:04:13,873 --> 00:04:15,465
100個もの特徴量がありうる、

120
00:04:15,480 --> 00:04:17,223
という話をした。

121
00:04:17,250 --> 00:04:18,756
例えば、x1は広さ、

122
00:04:18,756 --> 00:04:20,096
x2は寝室の数、

123
00:04:20,096 --> 00:04:21,963
x3は何階建てか、などなど。

124
00:04:21,963 --> 00:04:24,502
そのように、何百もの特徴量を持ちうる。

125
00:04:24,502 --> 00:04:26,896
そして多項式の例と違って、

126
00:04:26,920 --> 00:04:28,459
私たちは知らないのだ――

127
00:04:28,460 --> 00:04:29,826
私たちはシータ3やシータ4が

128
00:04:29,826 --> 00:04:32,641
高次の項ということを知らないのだ。

129
00:04:32,641 --> 00:04:34,515
だから、私たちは単にカバンの中に

130
00:04:34,540 --> 00:04:35,863
多くの特徴量を詰め込んだ、

131
00:04:35,863 --> 00:04:38,074
というだけなので、

132
00:04:38,100 --> 00:04:40,210
事前にどの特徴量があまり関係なさそうかを

133
00:04:40,260 --> 00:04:42,729
選び出すのは難しい。

134
00:04:42,729 --> 00:04:45,773
つまり私たちには100個とか101個のパラメータがあるだけで、

135
00:04:45,780 --> 00:04:47,340
そこからどれを選ぶべきかを

136
00:04:47,340 --> 00:04:48,987
知らない、

137
00:04:49,010 --> 00:04:50,445
どのパラメータを縮めるべきか

138
00:04:50,450 --> 00:04:54,272
分からない。

139
00:04:54,430 --> 00:04:56,237
だから正規化において私たちがやることは、

140
00:04:56,237 --> 00:04:58,438
コスト関数に対して、

141
00:04:58,438 --> 00:05:01,213
これが線形回帰のコスト関数だ。

142
00:05:01,213 --> 00:05:02,656
そして私がやることは、

143
00:05:02,660 --> 00:05:04,326
このコスト関数を修正して、

144
00:05:04,340 --> 00:05:06,246
すべてのパラメータを縮める。

145
00:05:06,270 --> 00:05:07,643
何故なら、

146
00:05:07,643 --> 00:05:09,059
どれを縮めたらいいのか

147
00:05:09,059 --> 00:05:10,440
知らないから。

148
00:05:10,440 --> 00:05:11,690
つまり、私はコスト関数を修正して

149
00:05:11,690 --> 00:05:16,732
最後に項を追加する。

150
00:05:17,390 --> 00:05:20,436
こんな感じ。だから大カッコも足しておく。

151
00:05:20,440 --> 00:05:22,212
おのおののパラメータを

152
00:05:22,212 --> 00:05:23,516
縮めるために

153
00:05:23,530 --> 00:05:25,510
正規化項を

154
00:05:25,560 --> 00:05:27,286
末尾に足す。

155
00:05:27,320 --> 00:05:28,745
つまりこの項は、私たちのすべてのパラメータ、

156
00:05:28,760 --> 00:05:30,747
シータ1, シータ2、シータ3、と

157
00:05:30,747 --> 00:05:32,746
シータ100までのすべてのパラメータを

158
00:05:32,746 --> 00:05:35,490
縮めるように機能する。

159
00:05:36,790 --> 00:05:39,629
ところで、慣例により、ここでの和は

160
00:05:39,629 --> 00:05:41,007
1から始まっている。

161
00:05:41,007 --> 00:05:43,341
つまりパラメータのシータ0が大きくなっても

162
00:05:43,360 --> 00:05:45,416
ペナルティを与えていない。

163
00:05:45,470 --> 00:05:46,435
iが0からnまで、ではななく、

164
00:05:46,435 --> 00:05:48,664
iが１からnまで、という

165
00:05:48,664 --> 00:05:50,185
慣習は、

166
00:05:50,190 --> 00:05:51,953
実際には、非常に小さな

167
00:05:51,960 --> 00:05:53,464
効果しかない。

168
00:05:53,490 --> 00:05:54,788
だからシータ0を

169
00:05:54,788 --> 00:05:56,221
含めても含めなくても、

170
00:05:56,221 --> 00:05:59,532
現実的には結果にはほとんど違いを生まない。

171
00:05:59,540 --> 00:06:01,804
だが慣例により、通常は、

172
00:06:01,804 --> 00:06:03,356
私たちはシータの1からシータ100までだけを

173
00:06:03,360 --> 00:06:06,084
正規化する。

174
00:06:06,084 --> 00:06:08,978
私たちの正規化した最適化目的の関数を、

175
00:06:08,978 --> 00:06:10,655
私たちの正規化したコスト関数をもう一度書き下そう。

176
00:06:10,655 --> 00:06:11,718
それはこんな風になる。

177
00:06:11,718 --> 00:06:13,903
Jのシータは、

178
00:06:13,970 --> 00:06:15,863
この右側の項は正規化項で、

179
00:06:15,863 --> 00:06:17,548
そしてここのラムダは

180
00:06:17,570 --> 00:06:23,950
正規化パラメータと呼ばれるもので、

181
00:06:23,973 --> 00:06:26,334
ラムダのやることは、

182
00:06:26,334 --> 00:06:28,480
二つの異なるゴールのトレードオフを

183
00:06:28,510 --> 00:06:30,636
制御することだ。

184
00:06:30,636 --> 00:06:32,478
最初のゴールは、最初のゴールの目的の関数で

185
00:06:32,500 --> 00:06:34,399
表されているものだが、

186
00:06:34,399 --> 00:06:36,081
訓練データに

187
00:06:36,090 --> 00:06:38,350
うまくフィットするようにトレーニングしたい、というもの。

188
00:06:38,390 --> 00:06:41,083
私たちはトレーニングセットにうまくフィットさせたい。

189
00:06:41,083 --> 00:06:42,954
そして二番目のゴールは、

190
00:06:42,954 --> 00:06:44,474
パラメータを小さく保っておきたい。

191
00:06:44,474 --> 00:06:46,053
これは二番目の項で表されている、

192
00:06:46,060 --> 00:06:49,103
正規化の目的関数の、正規化の項で。

193
00:06:49,103 --> 00:06:53,583
そしてラムダ、正規化のパラメータがやることは、

194
00:06:53,583 --> 00:06:55,937
これら二つのゴールの間の

195
00:06:55,937 --> 00:06:57,694
トレードオフを制御すること、

196
00:06:57,694 --> 00:06:58,938
トレーニングセットにうまくフィットさせるというゴールと

197
00:06:58,960 --> 00:07:00,562
そしてもう一つの

198
00:07:00,562 --> 00:07:02,043
パラメータシータを小さく保ちたい、

199
00:07:02,080 --> 00:07:05,688
オーバーフィットを避けるため、仮説を比較的シンプルに保ちたい、

200
00:07:05,688 --> 00:07:09,134
というゴールだ。

201
00:07:09,290 --> 00:07:11,026
私たちの住居の価格の予測の例では、

202
00:07:11,030 --> 00:07:13,026
前に、非常に高次の多項式で

203
00:07:13,030 --> 00:07:14,256
フィッティングすれば、

204
00:07:14,256 --> 00:07:15,968
非常に、いわゆるうねった関数、

205
00:07:15,968 --> 00:07:17,461
こんな感じ、

206
00:07:17,480 --> 00:07:19,020
こういう感じになるかもしれないのだった。

207
00:07:19,020 --> 00:07:22,460
もし高次の多項式で、

208
00:07:22,460 --> 00:07:24,120
すべての多項式の項の特徴量を

209
00:07:24,120 --> 00:07:26,038
含めておくならば。

210
00:07:26,038 --> 00:07:27,956
だが代わりに、確かにこれらの

211
00:07:27,970 --> 00:07:30,798
正規化された目的関数を使えば

212
00:07:30,798 --> 00:07:32,272
そこから得られるものは、

213
00:07:32,272 --> 00:07:34,332
それは実際には完全に二次関数という

214
00:07:34,340 --> 00:07:36,465
わけではないが、

215
00:07:36,490 --> 00:07:38,510
もっとスムーズでもっとシンプルなものとなる。

216
00:07:38,510 --> 00:07:39,870
そしてマゼンタ色のカーブが得られるだろう。

217
00:07:39,870 --> 00:07:42,261
これはたぶん、このデータには

218
00:07:42,261 --> 00:07:45,445
より良い仮説と言える。

219
00:07:45,445 --> 00:07:46,613
ここでも私は自覚しているが、

220
00:07:46,613 --> 00:07:47,919
何故パラメータを縮めることが、この効果を生むのかを理解するのは

221
00:07:47,919 --> 00:07:50,064
少し難しいかもしれない。

222
00:07:50,064 --> 00:07:51,668
だが正規化を自分で

223
00:07:51,690 --> 00:07:54,584
実装すれば、

224
00:07:54,650 --> 00:07:56,063
この効果を直接

225
00:07:56,090 --> 00:07:58,859
見ることができるだろう。

226
00:08:00,620 --> 00:08:02,777
正規化された線形回帰では、

227
00:08:02,777 --> 00:08:05,748
正規化のパラメータラムダが

228
00:08:05,748 --> 00:08:07,669
非常に大きい値にセットされると、

229
00:08:07,669 --> 00:08:09,542
起こることは、

230
00:08:09,542 --> 00:08:11,698
パラメータのシータ1,

231
00:08:11,698 --> 00:08:13,513
シータ2, シータ3, シータ4を

232
00:08:13,520 --> 00:08:15,207
非常に大きく

233
00:08:15,230 --> 00:08:17,409
ペナルティを課される。

234
00:08:17,430 --> 00:08:21,916
つまり、私たちの仮説がこの下にあるようなものだとして、

235
00:08:21,930 --> 00:08:23,674
最終的にシータ1, シータ2,

236
00:08:23,674 --> 00:08:24,913
シータ3, シータ4に、非常に重く

237
00:08:24,990 --> 00:08:26,145
ペナルティを課すと、

238
00:08:26,145 --> 00:08:29,463
結局、これらのパラメータはすべて0に近づく。

239
00:08:29,463 --> 00:08:32,240
シータ1が0に近づき、シータ2が0に近づき、

240
00:08:32,240 --> 00:08:34,410
シータ3とシータ4も

241
00:08:34,410 --> 00:08:36,646
結局は0に近づく。

242
00:08:36,646 --> 00:08:37,810
そうすると、それはまるで

243
00:08:37,810 --> 00:08:39,143
仮説のこれらの項を

244
00:08:39,160 --> 00:08:41,189
取り除いたような状態になり、

245
00:08:41,189 --> 00:08:43,597
つまり私たちはこの残った項だけの仮説を持っているような状態で、

246
00:08:43,597 --> 00:08:44,624
その残ったものはつまり、

247
00:08:44,630 --> 00:08:46,020
住居の価格は、イコール、

248
00:08:46,020 --> 00:08:48,624
シータ0と等しい、と言っているに近い。

249
00:08:48,650 --> 00:08:50,830
それは水平な直線をデータに

250
00:08:50,830 --> 00:08:54,679
フィッティングしているようなものだ。

251
00:08:54,679 --> 00:08:56,533
そしてこれは、アンダーフィッティングの

252
00:08:56,570 --> 00:08:58,773
例でもある。

253
00:08:58,773 --> 00:09:00,926
具体的にはこの仮説では、

254
00:09:00,950 --> 00:09:02,552
この直線で、これでは、

255
00:09:02,570 --> 00:09:04,063
トレーニングセットにうまくフィッティングできない。

256
00:09:04,070 --> 00:09:05,423
これは単なる平坦な直線だから。

257
00:09:05,423 --> 00:09:07,173
だからトレーニング手本の大半が近くにあるようなどこかには

258
00:09:07,173 --> 00:09:10,432
行くことができない。

259
00:09:10,432 --> 00:09:11,592
別の言い方をすると、

260
00:09:11,592 --> 00:09:13,697
この仮説は、あまりにも強い前提を

261
00:09:13,720 --> 00:09:15,410
置いている、あるいは

262
00:09:15,450 --> 00:09:17,091
あまりにも高いバイアスを置いている、と言える、

263
00:09:17,120 --> 00:09:18,446
住居の価格が単純にシータ0とイコールである、という、

264
00:09:18,460 --> 00:09:20,183
データとは明らかに

265
00:09:20,230 --> 00:09:22,123
矛盾しているにも関わらず。

266
00:09:22,123 --> 00:09:23,207
平坦な直線に

267
00:09:23,207 --> 00:09:25,648
フィッティングすることを選んでいる、

268
00:09:25,650 --> 00:09:28,230
水平な直線に。あまりうまく描けなかったが。

269
00:09:28,230 --> 00:09:30,447
こんな水平の、直線を

270
00:09:30,447 --> 00:09:33,059
データに。

271
00:09:33,060 --> 00:09:35,626
だから正規化がうまく行くためには、

272
00:09:35,626 --> 00:09:37,835
ある程度の注意が必要だ、

273
00:09:37,850 --> 00:09:39,903
正規化項のラムダを

274
00:09:39,903 --> 00:09:42,991
ちょうど良く選んでやるためには。

275
00:09:42,991 --> 00:09:44,908
そしてこのコースの後半で

276
00:09:44,920 --> 00:09:46,717
マルチセレクションの話をする時には、

277
00:09:46,717 --> 00:09:48,413
正規化のパラメータラムダを

278
00:09:48,420 --> 00:09:50,803
自動的に選ぶ、

279
00:09:50,810 --> 00:09:54,833
様々な方法も議論する。

280
00:09:54,833 --> 00:09:56,570
さて、以上が高正規化のアイデアと、

281
00:09:56,570 --> 00:09:58,254
そして正規化で用いるコスト関数が

282
00:09:58,254 --> 00:10:00,454
どんなものかの説明だ。

283
00:10:00,454 --> 00:10:01,885
続く2つのビデオで、

284
00:10:01,885 --> 00:10:03,736
これらのアイデアを用いて

285
00:10:03,750 --> 00:10:05,440
線形回帰とロジスティック回帰に

286
00:10:05,440 --> 00:10:07,111
適用することで、

287
00:10:07,111 --> 00:10:09,020
オーバーフィッティングを

288
00:10:09,060 --> 00:10:10,982
回避してみよう。
