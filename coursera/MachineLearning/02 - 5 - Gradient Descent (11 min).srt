1
00:00:00,000 --> 00:00:04,934
前に目的関数 J を定義した。

2
00:00:04,934 --> 00:00:09,634
このビデオでは、目的関数 J を最小化する最急降下法というアルゴリズムについて話す。

3
00:00:09,634 --> 00:00:14,275
実は最急降下法はより汎用的なアルゴリズムで、線形回帰以外でも使われる。

4
00:00:14,275 --> 00:00:18,916
実際には機械学習ではあちこちで使われている。

5
00:00:18,916 --> 00:00:23,791
そして後ほどこのクラスでは、最急降下法を使って他の関数も最小化する。

6
00:00:23,791 --> 00:00:27,845
線形回帰の目的関数 J だけではなく。

7
00:00:27,845 --> 00:00:32,558
だから、このビデオでは、最急降下法の説明に、任意の関数 J を使う。

8
00:00:32,558 --> 00:00:37,406
そして後のビデオで、このアルゴリズムを使って、

9
00:00:37,406 --> 00:00:43,332
それを特に線形回帰で使った目的関数 J に適用する。では、これが問題の設定だ。

10
00:00:43,332 --> 00:00:48,112
ある関数 J(theta 0, theta 1) がある。

11
00:00:48,112 --> 00:00:52,773
これは線形回帰の目的関数かもしれない。
最小化したいそれ以外のなんらかの関数かもしれない。

12
00:00:52,773 --> 00:00:56,801
そして、それを J(theta 0, theta1) の関数として

13
00:00:56,801 --> 00:01:01,174
最小化するアルゴリズムを見つけたい。

14
00:01:01,174 --> 00:01:05,793
余談だが、実は最急降下法は実はもっと一般的な関数にも適用される。

15
00:01:05,793 --> 00:01:10,994
だから、ある関数が、 J(theta 0, theta 1, theta 2,

16
00:01:10,994 --> 00:01:16,194
と theta n まで続く ) に対する関数であると想像してほしい。

17
00:01:16,405 --> 00:01:21,795
そして、この J(theta 0 から theta n) を theta 0 から theta n にかけて

18
00:01:21,795 --> 00:01:26,580
最小化したいとする。実は最急降下法はこのような

19
00:01:26,580 --> 00:01:31,368
もっと一般的な問題を解くためのアルゴリズムだが、簡潔さのためと、

20
00:01:31,368 --> 00:01:35,935
表記の簡明さのために、これ以降ビデオでは、2つのパラメータだけを表記する。

21
00:01:36,113 --> 00:01:41,097
これが最急降下法の考え方だ。何を行うかというと、

22
00:01:41,097 --> 00:01:45,882
最初になんらかの初期値を theta 0 と theta 1 に対し推定する。

23
00:01:45,882 --> 00:01:50,788
それはなんでも構わない。

24
00:01:50,788 --> 00:01:55,452
しかし、一般的な選択は theta 0 = 0、theta 1 = 0 と設定することだ。
単に 0 に初期化する。

25
00:01:55,452 --> 00:02:00,322
最急降下法で行うのは、theta 0 と theta 1 の値を少しずつ変え続けて、

26
00:02:00,322 --> 00:02:05,258
J(theta 0, theta 1) を減少させられないか試していくことだ。

27
00:02:05,258 --> 00:02:10,571
するといずれ最小値、あるいは、もしかして局所的最小値に到達する。

28
00:02:10,796 --> 00:02:16,106
では、最急降下法が何をするのか、図解を見てみよう。
例えば、この関数を最小化しようとしているとする。

29
00:02:16,106 --> 00:02:20,849
座標軸を見てほしい。これは、theta 0、theta 1 が横軸に、

30
00:02:20,849 --> 00:02:25,774
J は縦軸に取られている。だから、表面の高さが J を示しており、

31
00:02:25,774 --> 00:02:30,582
そしてこの関数を最小化したい。
まず始めに、(theta 0, theta 1) をどこかの点に設定する。

32
00:02:30,582 --> 00:02:35,375
だから、なんらかの値を (theta 0, theta 1) に取ると想像してほしい。

33
00:02:35,375 --> 00:02:39,934
そしてそれはこの関数の表面のどこかの点に対応する。

34
00:02:39,934 --> 00:02:44,201
だから (theta 0, theta 1) の値が何であれ、それはこの上のどこかの点となる。

35
00:02:44,201 --> 00:02:48,819
今回は (0, 0) としなかったが、時には他の値に初期化することがある。

36
00:02:48,819 --> 00:02:53,942
さて、この図が丘を表示していると想像してほしい。

37
00:02:53,942 --> 00:02:59,178
これが二つ丘がある緑の草の生えた公園の風景であると想像してみよう。

38
00:02:59,178 --> 00:03:04,618
そして、自分が実際に丘のその地点に立っていると想像してみる。

39
00:03:04,618 --> 00:03:09,990
この公園の小さな赤い丘の上だ。

40
00:03:09,990 --> 00:03:15,770
最急降下法で行うのは、ここで360度回転し、周囲を見渡して自問する、

41
00:03:15,770 --> 00:03:20,423
「もし、どこかの方向に小さく一歩踏み出すとしたら、

42
00:03:20,423 --> 00:03:25,320
そしてなるべく急いで斜面を降りたいとしたら、
もし降りたければどの方向にその一歩を踏み出すべきか、

43
00:03:25,320 --> 00:03:29,686
もしなるべく急いで実際に丘を下っていくには」と。

44
00:03:29,686 --> 00:03:34,465
丘のその地点に立ち、周りを見渡して、

45
00:03:34,465 --> 00:03:39,185
下りの小さな一歩を踏み出すのに最良の方向は、ほぼこちらだと見極めた。

46
00:03:39,185 --> 00:03:44,035
これで丘の上の新しい地点に移動した。

47
00:03:44,035 --> 00:03:49,430
また、周囲を見渡して自問する

48
00:03:49,430 --> 00:03:54,695
「下りの小さな一歩を踏み出すのに最良の方向はどれか」と。
そして、もう一歩踏み出すと、

49
00:03:54,695 --> 00:03:59,700
その方向に一歩移動する。そして、これを続ける。この新しい地点で周囲を見渡し、

50
00:03:59,700 --> 00:04:04,835
どの方向なら最も速く下に降りられるか決め、

51
00:04:04,835 --> 00:04:09,775
また一歩、また一歩、と続け、

52
00:04:09,970 --> 00:04:15,059
やがてこの局所的最小値に収束する。最急降下法には興味深い特性がある。

53
00:04:15,059 --> 00:04:19,682
この最初に最急降下法を実行した時、この地点から始めた。

54
00:04:19,682 --> 00:04:24,183
この地点から始めた。さて、最急降下法を実行する時に、

55
00:04:24,183 --> 00:04:29,232
ほんの数歩ほど右の地点から始めたとする。
最急降下法の初期値がその右上の地点だとする。

56
00:04:29,232 --> 00:04:34,159
このプロセスを繰り返して、その地点で立ち止まって、周りを見渡し、

57
00:04:34,159 --> 00:04:39,207
最も急な下り方面に一歩踏み出す。

58
00:04:39,207 --> 00:04:44,772
移動して、周囲を見渡す。また一歩移動し、これを繰り返す。

59
00:04:44,772 --> 00:04:50,570
もしほんの二歩ほど右から開始すると、最急降下法は、この右の二番目の

60
00:04:50,570 --> 00:04:56,236
局所的最適解に導く。

61
00:04:56,236 --> 00:05:01,602
だから、この最初の地点から開始すると、この局所的最適解に落ち着く。

62
00:05:01,602 --> 00:05:06,762
しかし、もし少しだけ別の場所から始めると、まったく別の局所的最適解に落ち着く。

63
00:05:06,762 --> 00:05:12,197
そしてこれが最急降下法の特性で、後でまた少しお話しする。

64
00:05:12,197 --> 00:05:17,425
さて、これが図解による説明だ。では、数学的に見てみよう。

65
00:05:17,425 --> 00:05:22,929
これが最急降下法アルゴリズムの定義だ。

66
00:05:22,929 --> 00:05:28,240
単に繰り返し、これを実行し、収束するまで続ける。

67
00:05:28,240 --> 00:05:33,543
パラメータ theta j から alpha 掛けるこの項を引いて theta j を更新する。

68
00:05:33,543 --> 00:05:39,129
さて、この式には色々なポイントがあるので

69
00:05:39,129 --> 00:05:45,030
それを少し分解しよう。まず、この表記、:= 。

70
00:05:45,030 --> 00:05:51,643
この := は代入を表記するために使うもので、これは代入演算子だ。

71
00:05:51,643 --> 00:05:57,790
だから、具体的には、もし A := B と書いたら、

72
00:05:57,790 --> 00:06:02,878
それはコンピュータでは、
これは B の値を取って、それを使って A の値を上書きするという意味だ。

73
00:06:02,878 --> 00:06:08,517
つまり、A を B の値と同じにするということだ。これは代入。

74
00:06:08,517 --> 00:06:13,674
また A := A+1 と書くこともできる。これは A の値を 1 インクリメントすることだ。

75
00:06:13,674 --> 00:06:18,969
一方、対照的に、もし 等号を使って A = B と書いたら、これは真理表明だ。

76
00:06:18,969 --> 00:06:26,067
だから、もし A = B と書いたら、

77
00:06:26,067 --> 00:06:31,006
私は A の値が B の値に等しいと表明していることになる。

78
00:06:31,006 --> 00:06:36,331
だから左側は、これはコンピュータ演算で、A の値をなんらかに設定する。

79
00:06:36,331 --> 00:06:41,399
右側は、これは表明で、A と B の値が同じであると主張している。

80
00:06:41,399 --> 00:06:46,274
A := A+1 と書くことができ、それが A を 1 インクリメントすることを意味するのだから、

81
00:06:46,274 --> 00:06:50,764
A = A + 1 とは決して書かないでほしい。これは間違いだ。

82
00:06:50,764 --> 00:06:55,704
A と A + 1 は絶対に同じ値にはなれない。

83
00:06:55,704 --> 00:07:05,733
これは、定義の最初の部分だ。この alpha は、学習率という数字だ。

84
00:07:05,733 --> 00:07:12,360
alpha の役割は、基本的に最急降下法で取る降下ステップの大きさを制御する。

85
00:07:12,360 --> 00:07:17,113
もし alpha が非常に大きい場合、それが対応するのは、

86
00:07:17,113 --> 00:07:21,925
非常に積極的な最急降下法のやり方となり、大きなステップで降下する。

87
00:07:21,925 --> 00:07:26,322
もし alpha が非常に小さければ、小刻みなステップで降下する。

88
00:07:26,322 --> 00:07:31,194
そして、これについては後ほど戻ってもう少しお話しする。
どのように alpha を設定するかなどについて。

89
00:07:31,194 --> 00:07:35,660
そして最後に、この項。これは導関数項だ。

90
00:07:35,660 --> 00:07:40,582
これについては今は話さないが、

91
00:07:40,582 --> 00:07:45,564
後でこの導関数を導出し、それが一体何かを説明する。

92
00:07:45,564 --> 00:07:50,547
皆さんの中には他の人より微分積分を知っている人もいると思うが、
もし微分積分をよく知らなくても、心配ない。

93
00:07:50,547 --> 00:07:55,469
この項について知る必要のあることは説明する。

94
00:07:55,469 --> 00:08:00,580
さて、もう一つ 最急降下法につて大事なポイントがある。

95
00:08:00,580 --> 00:08:05,837
それは最急降下法では、theta 0 と theta 1 を更新する。

96
00:08:05,837 --> 00:08:10,699
だから、この更新は  j = 0 と j = 1 に対して実行される。
よって theta 0 を更新し、theta 1を更新する。

97
00:08:10,699 --> 00:08:15,955
そして 最急降下法を実装する方法のポイントは、

98
00:08:15,955 --> 00:08:21,562
この式、この更新の式では、

99
00:08:21,562 --> 00:08:31,384
同時に theta 0 と theta 1 を更新すべきだという点だ。

100
00:08:31,384 --> 00:08:36,432
私が言いたいのは、この式では、

101
00:08:36,432 --> 00:08:40,975
theta 0 :=  theta 0 - 何か、を更新し、theta 1 :=  theta 1 - 何か、を更新する。

102
00:08:40,975 --> 00:08:45,834
これを実装する方法は、右辺を計算することだ。

103
00:08:45,834 --> 00:08:52,677
これを計算する。theta 0 と theta 1 の両方に対して。

104
00:08:52,677 --> 00:08:57,469
そして同時に theta 0 と theta 1 を更新する。

105
00:08:57,469 --> 00:09:02,024
では、その意味を説明する。これが、最急降下法の正しい実装方法、つまり同時更新だ。

106
00:09:02,024 --> 00:09:06,461
temp 0 = それ、と設定し、temp 1 = それ、と設定する。

107
00:09:06,461 --> 00:09:11,430
つまり基本的に右辺を計算する。そして右辺を計算して、

108
00:09:11,430 --> 00:09:15,926
変数 temp 0 と temp 1 に代入した後で、theta 0 と theta 1 を同時に更新する。

109
00:09:15,926 --> 00:09:20,245
これが正しい実装だ。それと対照的に、こちらが間違った実装方法だ。

110
00:09:20,245 --> 00:09:25,533
同時更新を行わないものだ。

111
00:09:25,533 --> 00:09:31,666
この間違った実装方法では、temp 0 を計算し、次に theta 0 を更新する。

112
00:09:31,666 --> 00:09:36,644
そして temp 1 を計算し、次に temp 1 を更新する。

113
00:09:36,644 --> 00:09:41,877
そして、右側と左側の実装方法の違いは、ここ、このステップを見ると

114
00:09:41,877 --> 00:09:46,791
この時点では、既に theta 0 を更新してしまっているので、

115
00:09:46,791 --> 00:09:51,897
theta 0 の新しい値を使ってこの導関数項を計算することになり、

116
00:09:51,897 --> 00:09:57,340
結果的に、左側と比べて temp 1 の値が異なってしまう。

117
00:09:57,340 --> 00:10:01,565
この式に theta 0 の新しい値を使っているからだ。

118
00:10:01,565 --> 00:10:05,852
だから、この右側のものは正しい最急降下法の実装方法ではない。

119
00:10:05,852 --> 00:10:09,916
なぜ同時更新が必要なのかについては説明はしない。

120
00:10:09,916 --> 00:10:14,617
単にこれが最急降下法を通常実装するやり方だ。

121
00:10:14,617 --> 00:10:18,735
後でこれについてはさらに話す。

122
00:10:18,735 --> 00:10:22,496
実は、同時更新を実装する方がより自然なのだ。

123
00:10:22,496 --> 00:10:26,665
人々が最急降下法について話す時は、常に同時更新という意味で使っている。

124
00:10:26,665 --> 00:10:30,630
もし非同時更新を実装しても、おそらく動作はすると思う。

125
00:10:30,630 --> 00:10:34,747
しかし、右側のアルゴリズムは人々が最急降下法として言及するものではなく、

126
00:10:34,747 --> 00:10:38,356
それは何か異なる特性をもつ別のアルゴリズムだ。

127
00:10:38,356 --> 00:10:42,220
色々な理由で、これは少し変わった動作をする可能性がある。

128
00:10:42,220 --> 00:10:46,626
そして皆さんがすべきなのは、最急降下法の同時更新を実装する。

129
00:10:46,626 --> 00:10:52,313
さて、これが最急降下法アルゴリズムの概要だ。

130
00:10:52,313 --> 00:10:56,998
次のビデオでは、導関数項の詳細について説明する。
書き出したが、まだ定義していないので。

131
00:10:56,998 --> 00:11:01,799
もし以前に微分積分の授業を受けたことがあり、

132
00:11:01,799 --> 00:11:06,367
導関数や偏導関数を知っている人は、導関数項がまさにそれと同じだとわかる。

133
00:11:06,367 --> 00:11:11,425
しかしたとえ微分積分に詳しくなくても、心配しなくていい。

134
00:11:11,425 --> 00:11:15,680
次のビデオですべての直感的理解が得られ、

135
00:11:15,680 --> 00:11:19,883
導関数項を計算するのに必要なことはすべて説明する。

136
00:11:19,883 --> 00:11:24,296
たとえ微分積分を見たことがなくても、偏導関数を見たことがなくても。

137
00:11:24,296 --> 00:11:28,288
以上です。次のビデオでは、十分に直感的理解が得られ

138
00:11:28,288 --> 00:11:30,180
最急降下法を応用できるようになると思う。
